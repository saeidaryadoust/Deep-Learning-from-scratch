{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOV95Mm81vCiEhE03iNG89P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"pKDF9PmtZ9a1","executionInfo":{"status":"ok","timestamp":1726318503560,"user_tz":-210,"elapsed":4298,"user":{"displayName":"saeed aryadoost","userId":"10774676178346520416"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","import torchvision\n"]},{"cell_type":"code","source":["in_channel = 1\n","num_classes = 10\n","input_size = 784\n","num_classes = 10\n","learning_rate = 0.001\n","batch_size = 64\n","num_epochs = 2"],"metadata":{"id":"A3NkA4VUdULh","executionInfo":{"status":"ok","timestamp":1726318503561,"user_tz":-210,"elapsed":15,"user":{"displayName":"saeed aryadoost","userId":"10774676178346520416"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class identity(nn.Module):\n","\n","    def __init__(self):\n","        super(identity, self).__init__()\n","\n","    def forward(self, x ):\n","      return x"],"metadata":{"id":"4OT_Bn8Dep3Z","executionInfo":{"status":"ok","timestamp":1726318503562,"user_tz":-210,"elapsed":13,"user":{"displayName":"saeed aryadoost","userId":"10774676178346520416"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#load pretrain model\n","model = torchvision.models.vgg16(pretrained=True)\n","print(model)\n","#weight dont change\n","for param in model.parameters():\n","    param.requires_grad = False\n","print('-------------------------------------------------------------')\n","model.avgpool = identity()\n","model.classifier =nn.Sequential(nn.Linear(512, 100),\n","                                nn.ReLU(),\n","                                nn.Linear(100, 10))\n","\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Or9F2LxYdkGJ","executionInfo":{"status":"ok","timestamp":1726318507315,"user_tz":-210,"elapsed":3765,"user":{"displayName":"saeed aryadoost","userId":"10774676178346520416"}},"outputId":"892c00b4-c567-4862-a715-5895da8fdf02"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")\n","-------------------------------------------------------------\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): identity()\n","  (classifier): Sequential(\n","    (0): Linear(in_features=512, out_features=100, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=100, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"YLPXone5d5mL","executionInfo":{"status":"ok","timestamp":1726318507315,"user_tz":-210,"elapsed":20,"user":{"displayName":"saeed aryadoost","userId":"10774676178346520416"}}},"execution_count":4,"outputs":[]},{"source":["# Load data\n","train_dataset = datasets.CIFAR10('cifar10_data', train=True, transform=transforms.ToTensor(), download=True) # Changed '' to a valid directory 'cifar10_data'\n","train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n","\n","test_dataset = datasets.CIFAR10('cifar10_data', train=False, transform=transforms.ToTensor(), download=True) # Changed '' to a valid directory 'cifar10_data'\n","test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n","\n","# Initialize network\n","model = torchvision.models.vgg16(pretrained=True) # Removed call to model object\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vxOxlGZneYJA","executionInfo":{"status":"ok","timestamp":1726318511735,"user_tz":-210,"elapsed":4439,"user":{"displayName":"saeed aryadoost","userId":"10774676178346520416"}},"outputId":"7d245e74-f1c0-473f-b871-6669345939a6"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["# Train network\n","for epoch in range(num_epochs):\n","    for batch_idx, (data, targets) in enumerate(train_loader):\n","        # Flatten data\n","        # data = data.reshape(data.shape[0], -1)\n","\n","        # Forward\n","        scores = model(data)\n","        loss = criterion(scores, targets)\n","\n","        # Backward\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        # Gradient descent or Adam step\n","        optimizer.step()\n"],"metadata":{"id":"OwhBZTvOeeC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def check_accuracy(loader, model):\n","    if loader.dataset.train:\n","        print('Checking accuracy on training data')\n","    else:\n","        print('Checking accuracy on test data')\n","\n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for x, y in loader:\n","            # x = x.reshape(x.shape[0], -1)\n","            scores = model(x)\n","            _, predictions = scores.max(1)\n","            num_correct += (predictions == y).sum().item()\n","            num_samples += predictions.size(0)\n","\n","        print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}%')\n","\n","    model.train()\n","\n","check_accuracy(train_loader, model)\n","check_accuracy(test_loader, model)\n"],"metadata":{"id":"YQ4jkeAWgp93","executionInfo":{"status":"aborted","timestamp":1726319667519,"user_tz":-210,"elapsed":12,"user":{"displayName":"saeed aryadoost","userId":"10774676178346520416"}}},"execution_count":null,"outputs":[]}]}