{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO4f7cNJPEQlHbpt2EF/bE3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n"],"metadata":{"id":"VlNiCEZUZCuO","executionInfo":{"status":"ok","timestamp":1726406865004,"user_tz":-210,"elapsed":9950,"user":{"displayName":"saeed aryadoost","userId":"10774676178346520416"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["in_channel = 1\n","num_classes = 10\n","input_size = 784\n","num_classes = 10\n","learning_rate = 0.001\n","batch_size = 64\n","num_epochs = 5"],"metadata":{"id":"mgbREFCrbx1Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CNN(nn.Module):\n","    def __init__(self, in_channels=1, num_classes=10):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n","        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n","\n","    def forward(self , x):\n","        x = F.relu(self.conv1(x))\n","        x = self.pool(x)\n","        x = F.relu(self.conv2(x))\n","        x = self.pool(x)\n","        x = x.reshape(x.shape[0], -1)\n","        x = self.fc1(x)\n","        return x\n","\n","\n","\n"],"metadata":{"id":"NCluFj_PZMeF","executionInfo":{"status":"ok","timestamp":1726406875225,"user_tz":-210,"elapsed":417,"user":{"displayName":"saeed aryadoost","userId":"10774676178346520416"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["model = CNN()\n","x = torch.randn(64, 1, 28, 28)\n","print(model(x).shape)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RAJemK_bZEx-","executionInfo":{"status":"ok","timestamp":1726181837556,"user_tz":-210,"elapsed":12,"user":{"displayName":"saeed aryadoost","userId":"10774676178346520416"}},"outputId":"085f7b4a-b68a-4394-f37f-ddf25b8d5988"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10])\n"]}]},{"cell_type":"code","source":["# Load data\n","train_dataset = datasets.MNIST('', train=True, transform=transforms.ToTensor(), download=True)\n","train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n","\n","test_dataset = datasets.MNIST('', train=False, transform=transforms.ToTensor(), download=True)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n","\n","# Initialize network\n","model = CNN()\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"],"metadata":{"id":"VrDCyB80ZGnH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train network\n","for epoch in range(num_epochs):\n","    for batch_idx, (data, targets) in enumerate(train_loader):\n","        # Flatten data\n","        # data = data.reshape(data.shape[0], -1)\n","\n","        # Forward\n","        scores = model(data)\n","        loss = criterion(scores, targets)\n","\n","        # Backward\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        # Gradient descent or Adam step\n","        optimizer.step()\n"],"metadata":{"id":"ewjUYSm4ZIr-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f27kCuKCZA7I","executionInfo":{"status":"ok","timestamp":1726181877841,"user_tz":-210,"elapsed":11389,"user":{"displayName":"saeed aryadoost","userId":"10774676178346520416"}},"outputId":"80cc69a1-592f-4283-8799-e98fff944271"},"outputs":[{"output_type":"stream","name":"stdout","text":["Checking accuracy on training data\n","Got 58527 / 60000 with accuracy 97.55%\n","Checking accuracy on test data\n","Got 9770 / 10000 with accuracy 97.70%\n"]}],"source":["\n","def check_accuracy(loader, model):\n","    if loader.dataset.train:\n","        print('Checking accuracy on training data')\n","    else:\n","        print('Checking accuracy on test data')\n","\n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for x, y in loader:\n","            # x = x.reshape(x.shape[0], -1)\n","            scores = model(x)\n","            _, predictions = scores.max(1)\n","            num_correct += (predictions == y).sum().item()\n","            num_samples += predictions.size(0)\n","\n","        print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct) / float(num_samples) * 100:.2f}%')\n","\n","    model.train()\n","\n","check_accuracy(train_loader, model)\n","check_accuracy(test_loader, model)\n"]}]}