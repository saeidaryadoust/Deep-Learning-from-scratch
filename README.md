# Deep Learning from Scratch

This repository explores the fundamentals of deep learning by implementing various neural network architectures from scratch, without relying on external libraries like TensorFlow or PyTorch. Dive deep into the math and code behind these models, gaining a comprehensive understanding of their inner workings.

## Includes:

* **Basic Neural Networks:** Perceptrons, Multilayer Perceptrons, and Activation Functions.
* **Convolutional Neural Networks (CNNs):** Convolutional layers, pooling layers, and image classification examples.
* **Recurrent Neural Networks (RNNs):** Recurrent layers, LSTM, and text processing examples.
* **Generative Adversarial Networks (GANs):** Generator and discriminator networks, and image generation examples.
* **Famous Architectures:** Implementations of LeNet, ResNet, and GoogleNet.

## Famous Architectures:

### LeNet
LeNet is a pioneering convolutional neural network designed for digit recognition. It features:
- **Convolutional and Pooling Layers:** Capture spatial hierarchies in images.
- **Fully Connected Layers:** Perform classification based on extracted features.

### ResNet
ResNet introduces residual learning, enabling the training of deeper networks. Key features include:
- **Residual Blocks:** Facilitate gradient flow through identity mappings.
- **Deep Network Capability:** Achieves state-of-the-art performance by addressing the vanishing gradient problem.

### GoogleNet (Inception)
GoogleNet uses Inception modules to efficiently handle multi-scale features. It includes:
- **Inception Modules:** Combine multiple convolutional operations to capture various features.
- **Parameter Efficiency:** Achieves high accuracy with fewer parameters.

## Learn by Building:

This repository is ideal for those who want to truly understand the foundations of deep learning. By implementing these models from scratch, you'll gain a deeper appreciation for the complexity and power of these algorithms.

